{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankuj/teaching/blob/main/nlp_lab_day_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhE_ve2CMku1"
      },
      "source": [
        "\n",
        "<br>\n",
        "RNN Practical — Intro to Recurrent Neural Networks<br>\n",
        "Topics: Motivation, Basics, Architectures (One-to-Many, Many-to-One, etc.), Shared Parameters<br>\n",
        "Instructions: Complete each task by filling in the \"Your answer here\" sections.<br>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eut5NBEdMku6"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzWjX89mMku-"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 1: RNN Architectures <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlDX2hiTMku-"
      },
      "outputs": [],
      "source": [
        "def task1_architectures():\n",
        "    \"\"\"\n",
        "    Identify the correct RNN architecture (One-to-One, One-to-Many, Many-to-One, Many-to-Many)\n",
        "    for the following scenarios:\n",
        "    a) Sentiment analysis of a sentence -> single label\n",
        "    b) Music generation from a single start token -> output sequence\n",
        "    c) Named entity recognition: tag each word in a sentence\n",
        "    d) Machine translation: source sentence -> target sentence\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "    # a) Many-to-One\n",
        "    # b) One-to-Many\n",
        "    # c) Many-to-Many\n",
        "    # d) Many-to-Many (encoder-decoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz1xbYovMkvA"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 2: Shared Parameters <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UlHXaMJMkvB"
      },
      "outputs": [],
      "source": [
        "def task2_shared_parameters():\n",
        "    \"\"\"\n",
        "    Explain shared parameters in an RNN.\n",
        "    Compute parameter counts for an example:\n",
        "      input size d=4, hidden size h=3, sequence length T=10\n",
        "    \"\"\"\n",
        "    # Your answer here:\n",
        "    '''\n",
        "    In RNN, we keep using the same three matricies for processing each token in the sequence: Wx, Wh, Wy.\n",
        "\n",
        "    Shared parameters count:\n",
        "      - Wx = d*h = 4*3 = 12\n",
        "      - Wh: h*h = 3*3 = 9\n",
        "      - bias: 3 (size of h)\n",
        "      - Wy: depends on the output\n",
        "\n",
        "      - total count = 12 + 9 + 3 + Wy\n",
        "\n",
        "\n",
        "\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hMyzZbkLMkvB"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 3: Manual Forward Pass <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nlcGh9oLMkvC"
      },
      "outputs": [],
      "source": [
        "def task3_manual_forward_pass():\n",
        "    \"\"\"\n",
        "    Compute hidden states manually for a small RNN using np.tanh.\n",
        "    Input sequence length T=3, input size=2, hidden size=2\n",
        "    \"\"\"\n",
        "    x_seq = [np.array([0.5, -1.0]),\n",
        "             np.array([1.0, 0.0]),\n",
        "             np.array([-0.5, 0.5])]\n",
        "    h_prev = np.zeros(2)\n",
        "    W_xh = np.array([[0.6, -0.2],\n",
        "                     [0.1,  0.5]])\n",
        "    W_hh = np.array([[0.3, 0.4],\n",
        "                     [-0.2, 0.2]])\n",
        "    b_h = np.array([0.0,0.1])\n",
        "    h_list = []\n",
        "\n",
        "    # Your code here\n",
        "    for t in range(len(x_seq)):\n",
        "        h_t = np.tanh(np.dot(x_seq[t], W_xh) + np.dot(h_prev, W_hh) + b_h)\n",
        "        h_list.append(h_t)\n",
        "        h_prev = h_t\n",
        "\n",
        "    return h_list\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ORsqt1mMkvC"
      },
      "source": [
        "------------------------------<br>\n",
        "Task 4: NumPy RNN Cell Implementation <br>\n",
        "------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "lSsfHVNCMkvD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fe1966-8cad-4341-c4a8-7fb041e4fbdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " y_pred: [0.32929808 0.67070192]\n",
            " y_pred: [0.82727313 0.17272687]\n",
            " y_pred: [0.04731087 0.95268913]\n",
            " y_pred: [0.89906372 0.10093628]\n",
            "predictions , labels\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([np.int64(1), np.int64(0), np.int64(1), np.int64(0)], array([1, 0, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "def task4_numpy_rnn_cell():\n",
        "    \"\"\"\n",
        "    Implement a simple Many-to-One RNN in NumPy.\n",
        "    Use rnn_forward to compute h_T, then compute a readout: y = W_hy h_T + b_y\n",
        "    Predict class = argmax(y)\n",
        "    \"\"\"\n",
        "\n",
        "    # Toy dataset\n",
        "    toy_sequences = [\n",
        "        [np.array([1.0,0.5]), np.array([0.2,0.1]), np.array([0.3,-0.1])],\n",
        "        [np.array([-0.5,-0.4]), np.array([0.1,-0.2]), np.array([-0.3,-0.1])],\n",
        "        [np.array([0.8,0.2]), np.array([0.5,0.4]), np.array([0.1,0.2])],\n",
        "        [np.array([-0.6,-0.2]), np.array([-0.4,-0.3]), np.array([0.0,-0.1])]\n",
        "    ]\n",
        "    labels = np.array([1,0,1,0]) # no need to use the labels\n",
        "\n",
        "    # answer:\n",
        "\n",
        "    # x (1x2)\n",
        "    # Wxh (2x2)\n",
        "    # Whh (2x2)\n",
        "    # Why (1x2)\n",
        "\n",
        "    # final output will be h_t=n (2x2) @ W_y (2x1) -> 2x1\n",
        "\n",
        "\n",
        "\n",
        "    input_size = 2 # 2 dim\n",
        "    hidden_size = 2 # has to be consistent\n",
        "    output_size = 2 # For binary classification\n",
        "\n",
        "    # Initialize weights and biases (randomly for demonstration)\n",
        "    W_xh = np.random.randn(input_size, hidden_size)\n",
        "    W_hh = np.random.randn(hidden_size, hidden_size)\n",
        "    b_h = np.zeros(hidden_size)\n",
        "    W_hy = np.random.randn(hidden_size, output_size)\n",
        "    b_y = np.zeros(output_size)\n",
        "\n",
        "\n",
        "    predictions = []\n",
        "    for sequence in toy_sequences:\n",
        "        h_prev = np.zeros(hidden_size)\n",
        "        for x_t in sequence:\n",
        "            h_t = np.tanh(np.dot(x_t, W_xh) + np.dot(h_prev, W_hh) + b_h)\n",
        "            h_prev = h_t\n",
        "\n",
        "        # Compute y\n",
        "        y_pred = np.dot(h_prev, W_hy) + b_y\n",
        "        y_pred = np.exp(y_pred) / np.sum(np.exp(y_pred)) # normalize with softmax\n",
        "\n",
        "        print(f\" y_pred: {y_pred}\")\n",
        "        predicted_class = np.argmax(y_pred)\n",
        "        predictions.append(predicted_class)\n",
        "    print(\"predictions , labels\")\n",
        "    return predictions, labels\n",
        "\n",
        "\n",
        "task4_numpy_rnn_cell()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Goal:\n",
        "- Introduction to tensors in PyTorch\n",
        "- Build a simple RNN-based classifier\n",
        "\n",
        "Dataset:\n",
        "- We will classify short sequences of numbers as \"increasing\" or \"decreasing\"\n",
        "  Example:\n",
        "    [1, 2, 3, 4] → Label: 1 (increasing)\n",
        "    [5, 3, 1, 0] → Label: 0 (decreasing)\n",
        "\n",
        "----------------------------------------------------\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# ====================================================\n",
        "# STEP 1: Create a Tiny Synthetic Dataset\n",
        "# ====================================================\n",
        "\n",
        "def generate_data(num_samples=100, seq_len=4):\n",
        "    X = []\n",
        "    y = []\n",
        "    for _ in range(num_samples):\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            seq = torch.sort(torch.rand(seq_len))[0]   # Increasing\n",
        "            label = 1\n",
        "        else:\n",
        "            seq = torch.sort(torch.rand(seq_len), descending=True)[0]  # Decreasing\n",
        "            label = 0\n",
        "        X.append(seq.unsqueeze(-1))  # Shape: (seq_len, input_size=1)\n",
        "        y.append(label)\n",
        "    return torch.stack(X), torch.tensor(y)\n",
        "\n",
        "X, y = generate_data()\n",
        "# X shape → (batch_size=100, seq_len=4, input_size=1)\n",
        "# y shape → (batch_size=100)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 2: Define a Simple RNN Classifier\n",
        "# ====================================================\n",
        "\n",
        "class RNNClassifier(nn.Module):\n",
        "    def __init__(self, input_size=1, hidden_size=8, num_classes=2):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "      pass\n",
        "\n",
        "\n",
        "model = RNNClassifier()\n",
        "print(model)\n",
        "\n",
        "# ====================================================\n",
        "# STEP 3: Train the Model\n",
        "# ====================================================\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "# ====================================================\n",
        "# STEP 4: Test the Model on New Data\n",
        "# ====================================================\n",
        "\n",
        "test_X, test_y = generate_data(num_samples=10)\n",
        "\n",
        "print(\"\\nPredictions vs Actual:\")"
      ],
      "metadata": {
        "id": "Nxyi_7bfR1vi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}